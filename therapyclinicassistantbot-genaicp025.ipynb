{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11408190,"sourceType":"datasetVersion","datasetId":7145507}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Therapy Clinic Assistant Chatbot-Google GenAI Capstone Project 2025**","metadata":{}},{"cell_type":"markdown","source":"## Introduction\n\nIn this notebook, a generative AI-powered virtual support agent is built tailored for a psychology and consulting center. The goal is to create an empathetic, intelligent assistant that:\n- Answers client FAQs with warmth and clarity\n- Supports resource delivery and appointment flow\n- Leverages Gen AI capabilities including **few-shot prompting, embeddings + RAG, and structured output**\n- Receives clients information to book an appointment for them\n- Makes conversations so clients feel welcomes and supported there.\n- Feel free to check out the [Weblog](http://) and the [Youtube video](http://) about this project.\n\nThis project is part of the **Google Gen AI Intensive Course Capstone 2025Q1**.\n\nThank you and appriciate if you could comment and share your thoughts.\n","metadata":{}},{"cell_type":"markdown","source":"** BEFORE RUNNING:**\nPlease wait patiently until dependencies are downloaded, it takes couple minutes.\nIn order to run some sells you need to input some data, please fill the input tabs with correct info.\n","metadata":{}},{"cell_type":"code","source":"!pip install -qU \"google-genai==1.7.0\"\n!pip install -q sentence-transformers faiss-cpu\n\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nfrom sentence_transformers import SentenceTransformer, util\nimport numpy as np \nimport faiss # for similarity in search\nfrom IPython.display import Markdown, display # Display and Print prettier\n\n# Checking the dataset inquiry \nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T00:37:08.452802Z","iopub.execute_input":"2025-04-19T00:37:08.453106Z","iopub.status.idle":"2025-04-19T00:39:46.175342Z","shell.execute_reply.started":"2025-04-19T00:37:08.453083Z","shell.execute_reply":"2025-04-19T00:39:46.174212Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"2025-04-19 00:39:22.305382: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745023162.573888      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745023162.654653      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/input/therapy-centre-faqs/Therapy-Centre-FAQs.json\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\nfrom google.api_core import retry\n\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\ngenai.models.Models.generate_content = retry.Retry(\n    predicate=is_retriable)(genai.models.Models.generate_content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T00:39:49.404545Z","iopub.execute_input":"2025-04-19T00:39:49.405383Z","iopub.status.idle":"2025-04-19T00:39:50.712442Z","shell.execute_reply.started":"2025-04-19T00:39:49.405351Z","shell.execute_reply":"2025-04-19T00:39:50.711391Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n\nclient = genai.Client(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T00:39:53.234428Z","iopub.execute_input":"2025-04-19T00:39:53.234750Z","iopub.status.idle":"2025-04-19T00:39:53.945338Z","shell.execute_reply.started":"2025-04-19T00:39:53.234727Z","shell.execute_reply":"2025-04-19T00:39:53.944142Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"markdown","source":"\n**Lets Check The FAQ Questions:**\nThere are twenty FAQ items in this dataset.","metadata":{}},{"cell_type":"code","source":"import json\nfaq_path = \"/kaggle/input/therapy-centre-faqs/Therapy-Centre-FAQs.json\"\nwith open(faq_path, \"r\") as f:\n    faq_data = json.load(f)\nmd_output = \"|Questions | Answer | \\n|----------|----------|\\n\"\nfor item in faq_data[:5]: # There are 15 [0-14] FAQ items in this dataset as a sample\n    md_output += f\"| {item['question']} | {item['answer']} |\\n\"\ndisplay(Markdown(md_output))    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T00:40:00.905606Z","iopub.execute_input":"2025-04-19T00:40:00.905933Z","iopub.status.idle":"2025-04-19T00:40:00.919806Z","shell.execute_reply.started":"2025-04-19T00:40:00.905910Z","shell.execute_reply":"2025-04-19T00:40:00.918905Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"|Questions | Answer | \n|----------|----------|\n| What services do you offer? |  provide individual therapy, couples therapy, life coaching, and career consultation sessions virtualy. |\n| Do you only offer online sessions? | Yes, all our services are available through secure virtual sessions, which are easy to access from anywhere. However, we also have a few in-person options available for local clients. Please remebebr that the fisrt session is always virtual. |\n| How do I book a session? | You can book online through our secure portal you can see your options by clicking on the \"Book Now\". We'll help you find the best time slot. |\n| Is therapy confidential? | Yes. All therapy sessions are strictly confidential, in accordance with legal and ethical guidelines. Exceptions apply only in rare safety-related cases. |\n| How much does a session cost? | Our sessions range from $50 to $160 depending on the service and provider. We offer sliding scale rates in some cases. |\n"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"Next is **Embeddings for the FAQ items**, by this step I transform the questions into vector representations for *semantic search* (I want to make sure if a client uses other words or phrases which mean the same as one my FAQ items the bot will catch it). Next, I use **Retrieval Augmented Generation (RAG)** feature to test the performance of my bot handling the FAQ questions.\n\n\nOther momdels like flan-t5 or gemma could be used, during the next steps it will be explained why this model is chosen.","metadata":{}},{"cell_type":"code","source":"\"\"\"generate embeddings using the 'all-MiniLM-L6-V2' model from `sentence-stransformers`\"\"\"\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n\nquestions = [item['question'] for item in faq_data]\nanswers = [item['answer'] for item in faq_data]\nquestion_embeddings = model.encode(questions, convert_to_tensor=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T00:40:05.032106Z","iopub.execute_input":"2025-04-19T00:40:05.032495Z","iopub.status.idle":"2025-04-19T00:40:16.188242Z","shell.execute_reply.started":"2025-04-19T00:40:05.032471Z","shell.execute_reply":"2025-04-19T00:40:16.187019Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b22c2068b10c401881f9ed14cf6b0cd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76df5fa596724202a58d2c27c3a9dda4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0a5698774364ee5902c1009d3d26a86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a67bae2a9fd46c4a36d824e9c796dc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f481f142b36d4bdd9907e81ec04d6d6c"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3940c87390b049d3b7340e176db4cf08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d1ef69d753c4fdea9eeda066178b934"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"519e2ca686c5462b81fe47fdad16bce9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c944abccf3484774ac72a94648916c95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39407a26756841b1829cec63b5aca4e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c44a4ec4bb9b476db5f6d565464e186d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c89032fc3524c5fb7f94954344db9cc"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Using FAISS to structure a similarity index over the FAQ embeddingd.\n\ndimension = len(question_embeddings[0])\nindex = faiss.IndexFlatL2(dimension)\nindex.add(np.array(question_embeddings))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T00:42:07.269859Z","iopub.execute_input":"2025-04-19T00:42:07.270200Z","iopub.status.idle":"2025-04-19T00:42:07.277087Z","shell.execute_reply.started":"2025-04-19T00:42:07.270177Z","shell.execute_reply":"2025-04-19T00:42:07.275834Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"Creating **answer function** with **RAG**","metadata":{}},{"cell_type":"code","source":"def get_faq_item(user_query, top_k=1): \n    query_embedding = model.encode([user_query])[0]\n    D, I = index.search(np.array([query_embedding]), top_k) # Nearest neighbor search fron faiss, it finds the closest vector to the query vector.\n    return answers[I[0][0]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T00:42:03.677785Z","iopub.execute_input":"2025-04-19T00:42:03.678223Z","iopub.status.idle":"2025-04-19T00:42:03.684143Z","shell.execute_reply.started":"2025-04-19T00:42:03.678193Z","shell.execute_reply":"2025-04-19T00:42:03.683038Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# For example\nuser_input = \"I want to try a session and see how it goes, How can I book a one?\"\nresponse = get_faq_item(user_input)\ndisplay(Markdown(f\"**User:** {user_input}<br>**TherapyRobo:** {response}\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T00:42:09.893175Z","iopub.execute_input":"2025-04-19T00:42:09.893573Z","iopub.status.idle":"2025-04-19T00:42:09.946560Z","shell.execute_reply.started":"2025-04-19T00:42:09.893538Z","shell.execute_reply":"2025-04-19T00:42:09.944803Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d12328f530b748a984ac4d0ecd32c6e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**User:** I want to try a session and see how it goes, How can I book a one?<br>**TherapyRobo:** You can book online through our secure portal you can see your options by clicking on the \"Book Now\". We'll help you find the best time slot."},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"Great, we see that FAQ bot is working, but clearly our purpose is beyond that, lets continue...","metadata":{}},{"cell_type":"markdown","source":"## **Few Shot Prompting**\n\nIn this step by the help of the Gen AI model, the responses sound emothionaly intelligent, empathic and reliable. ","metadata":{}},{"cell_type":"code","source":"few_shot_prompt = [\n    {\n        \"user\": \"I'm nervous about starting therapy.\", \n        \"bot\": \"That’s completely understandable. Many people feel that way. Would you like to know what to expect in your first session?\"\n    },\n    {\n        \"user\": \"I’ve never talked to anyone about this before.\", \n        \"bot\": \"Thank you for trusting us. You’ve taken a brave first step. We’re here to support you.\"\n    },\n    {\n        \"user\": \"I feel overwhelmed lately and don't know who to talk to.\", \n        \"bot\": \"You’re not alone in feeling that way. We're here to help you take small steps toward feeling better. Would it help to talk about how your day usually goes?\"\n    },\n    {\n        \"user\": \"Is therapy confidential?\", \n        \"bot\": \"Yes, confidentiality is very important to us. We can explain what that means and when exceptions might apply.\"\n    },\n    {\n        \"user\": \"What if I don’t feel comfortable with my therapist?\", \n        \"bot\": \"That's absolutely understandable. Finding the right fit is important, and we're happy to help you switch to someone you feel safe with—no pressure.\"\n    }]\n\ndef few_shot(user_message):\n     prompt = \"\"\"\n        You are TherapyRobo — a supportive, emotionally intelligent virtual therapist assistant. \n        You are responding to a client who may be skeptical, nervous, or emotionally guarded.\n        \n        Your tone should be kind, validating, human-like, and never robotic or overly promotional. \n        You may acknowledge their hesitation, and gently offer support or booking info if appropriate.\n        \n        The clinic website is: https://TherapyClinic.com  \n        The phone number is: +1 234 000 1111\n        \"\"\"\n     for ex in few_shot_prompt:\n        prompt += f\"User: {ex['user']}\\nTherapyRobo: {ex['bot']}\\n\"\n     prompt += f\"User: {user_message}\\nTherapyRobo:\"\n     return prompt\n\n\nprompt = f\"\"\"You are simulating a random client asking FAQ style question from the Therapybot chatbox,\n    Don't use \"ok, here it goes\". remember it's a typed conversation,don't type sounds.you should sound like a human, nice, stressed, angry, tired. Never bold a word and do not make sounds like: ugh. However you're questions should be reasonable and short\"\"\"\n    \nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=prompt,\n    config=types.GenerateContentConfig(\n        temperature=0.1,\n        max_output_tokens=256\n    )\n)\nsample_client = response.text.strip()\nfaq_prompt = few_shot(sample_client)\n\nlines = faq_prompt.strip().split(\"\\n\")\ninstruction = lines[0]\ndef gemini_faq_handler(prompt_text, display_response=True): #prompt_text should be a variable = few_shot(client message here)\n    \"\"\"\n    Generate a short response from a given prompt.\n    The clinic website is: https://TherapyClinic.com and Phone number:+1 234 000 1111\n    Args:\n        prompt_text (str): The full prompt to send to the Gemini model.\n        display_response (bool): If True, the result will be displayed using Markdown.\n\n    Returns:\n        str: The raw response text from Gemini.\n    \"\"\"\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=prompt_text,\n        config=types.GenerateContentConfig( \n            temperature=0.5,\n            top_p=1,\n            top_k=1,\n            max_output_tokens=300\n        )\n    )\n    return response.text.strip()\n    \nrobo_response = gemini_faq_handler(faq_prompt)\ndisplay(Markdown(f\"**Few-shot Prompt**\\n\\n**Instruction**: {instruction}\\n\\n**User**: {sample_client}\\n\\n**TherapyRobo**: {robo_response}\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T02:35:32.480383Z","iopub.execute_input":"2025-04-19T02:35:32.480737Z","iopub.status.idle":"2025-04-19T02:35:33.604781Z","shell.execute_reply.started":"2025-04-19T02:35:32.480717Z","shell.execute_reply":"2025-04-19T02:35:33.603600Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**Few-shot Prompt**\n\n**Instruction**: You are TherapyRobo — a supportive, emotionally intelligent virtual therapist assistant. \n\n**User**: Hey, I'm just wondering... what if I feel like my therapist isn't really listening to me? It's kinda frustrating.\n\n**TherapyRobo**: I hear you. It's frustrating when you feel like you're not being heard, especially in therapy. A good therapeutic relationship relies on feeling understood. If that happens, it's okay to talk to your therapist about it directly. If that feels too difficult, we can also help you explore other options to find a better fit. We want you to feel comfortable and supported."},"metadata":{}}],"execution_count":117},{"cell_type":"markdown","source":"## **Document Parsing**\n\nStrucring information taken from simulated a session intake form received from a client. XXXPDF FormXXX","metadata":{}},{"cell_type":"code","source":"client_form = \"\"\"\nClient Name: Julia Anderson\nPhone Number: 200-000-1000\nEMail: client@gmail.com\nAge: 28\nType of therapy: Single\nPreferred Therapist: Dr. Sam\nReason for Visit: Feeling overwhelmed and anxious, also trouble falling sleep\nAvailability: Mondays and Wednesdays after 3 PM\nUrgency Level: Moderate\nInsurance: Dejardins\n\"\"\"\n\ninstruction_prompt = f\"\"\"You are an AI assistant helping a therapy clinic extracting structured data from their patients intake forms.\nRead the followinf form and extract the data in JSON format with the following fields:\n-Name\n-PhoneNumber\n-Email\n-Age\n-Type_of_therapy\n-Preffered_therapist\n-Reason_for_visit\n-Availability\n-Urgency\n-Insurance_company\nIntake_form: {client_form}\n\nReturn only a valid JSON object.\"\"\"\n\nresponse = client.models.generate_content(\n    model = \"gemini-2.0-flash\",\n    contents = instruction_prompt,\n    config = types.GenerateContentConfig(\n        temperature=0.1,\n        max_output_tokens=256\n    )\n)\nstructured_form_data = response.text.strip()\ndisplay(Markdown(f\"**Structured Intake Form Data In JSON**:\\n\\n```json\\n{structured_form_data}\\n```\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T00:42:29.735195Z","iopub.execute_input":"2025-04-19T00:42:29.735600Z","iopub.status.idle":"2025-04-19T00:42:30.593233Z","shell.execute_reply.started":"2025-04-19T00:42:29.735577Z","shell.execute_reply":"2025-04-19T00:42:30.592233Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**Structured Intake Form Data In JSON**:\n\n```json\n```json\n{\n  \"Name\": \"Julia Anderson\",\n  \"PhoneNumber\": \"200-000-1000\",\n  \"Email\": \"client@gmail.com\",\n  \"Age\": \"28\",\n  \"Type_of_therapy\": \"Single\",\n  \"Preffered_therapist\": \"Dr. Sam\",\n  \"Reason_for_visit\": \"Feeling overwhelmed and anxious, also trouble falling sleep\",\n  \"Availability\": \"Mondays and Wednesdays after 3 PM\",\n  \"Urgency\": \"Moderate\",\n  \"Insurance_company\": \"Dejardins\"\n}\n```\n```"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"Now to ask the user to provide the following information:\n\n> For the sake of the project, instead of receiving information from the user, we are generating it by gemini model, find the more interactive version at github. copy paste the code in this cell, no need to change anything, have fun!","metadata":{}},{"cell_type":"code","source":"def gemini_fill(question):\n    prompt = f\"\"\"You are simulating a random client filling out an intake form at a therapy clinic. Sometimes you are stressed, angry, upset, troubled, or tired.\nGive a realistic, short answer for the following question, do not make sounds like `ugh`:\n{question}\nOnly return the answer without explanation.\"\"\"\n    \n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=prompt,\n        config=types.GenerateContentConfig(\n            temperature=0.7,\n            max_output_tokens=256\n        )\n    )\n    return response.text.strip()\n\nintake_fields = [\n    {\"key\": \"name\", \"question\": \"What is your full name?\"},\n    {\"key\": \"phone_number\", \"question\": \"May I have your phone number?\"},\n    {\"key\": \"email\", \"question\": \"What's your email address?\"},\n    {\"key\": \"age\", \"question\": \"How old are you?\"},\n    {\"key\": \"type_of_therapy\", \"question\": \"Are you looking for individual, couples, or family therapy?\"},\n    {\"key\": \"preferred_therapist\", \"question\": \"Do you have a preferred therapist?\"},\n    {\"key\": \"reason_for_visit\", \"question\": \"Can you briefly describe your reason for seeking therapy?\"},\n    {\"key\": \"availability\", \"question\": \"When are you generally available for sessions?\"},\n    {\"key\": \"urgency\", \"question\": \"How urgent is your situation? (e.g., low, moderate, high)\"},\n    {\"key\": \"insurance_company\", \"question\": \"What insurance company do you use, if any?\"}\n]\n\ndef collect_intake_info(fields):\n    collected_data = {}        \n    conversation_log = \"\"      \n\n    for field in fields:\n        question = field[\"question\"]\n        answer = gemini_fill(question)\n        collected_data[field[\"key\"]] = answer\n        conversation_log += f\"**TherapyBot:** {question}\\n**Client:** {answer}\\n\\n\"\n\n    return collected_data, conversation_log.strip()\n\nclient_intake, intake_conversation = collect_intake_info(intake_fields)\n\ndisplay(Markdown(\"**This is a random reply. If you'd like to insert your answers manually, copy and paste the GitHub code.**\"))\ndisplay(Markdown(\"**Starting to fill intake form ...**\"))\ndisplay(Markdown(intake_conversation))  # full conversation\nprint(json.dumps(client_intake, indent=2))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T01:04:27.737595Z","iopub.execute_input":"2025-04-19T01:04:27.737988Z","iopub.status.idle":"2025-04-19T01:04:31.695600Z","shell.execute_reply.started":"2025-04-19T01:04:27.737964Z","shell.execute_reply":"2025-04-19T01:04:31.694037Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**This is a random reply. If you'd like to insert your answers manually, copy and paste the GitHub code.**"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**Starting to fill intake form ...**"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**TherapyBot:** What is your full name?\n**Client:** Robert Smith\n\n**TherapyBot:** May I have your phone number?\n**Client:** 555-123-4567\n\n**TherapyBot:** What's your email address?\n**Client:** [client_email@example.com]\n\n**TherapyBot:** How old are you?\n**Client:** 34\n\n**TherapyBot:** Are you looking for individual, couples, or family therapy?\n**Client:** Individual.\n\n**TherapyBot:** Do you have a preferred therapist?\n**Client:** No preference.\n\n**TherapyBot:** Can you briefly describe your reason for seeking therapy?\n**Client:** I'm having trouble managing my anger and it's affecting my relationships.\n\n**TherapyBot:** When are you generally available for sessions?\n**Client:** Evenings after work, and maybe Saturday mornings.\n\n**TherapyBot:** How urgent is your situation? (e.g., low, moderate, high)\n**Client:** High\n\n**TherapyBot:** What insurance company do you use, if any?\n**Client:** Blue Cross Blue Shield."},"metadata":{}},{"name":"stdout","text":"{\n  \"name\": \"Robert Smith\",\n  \"phone_number\": \"555-123-4567\",\n  \"email\": \"[client_email@example.com]\",\n  \"age\": \"34\",\n  \"type_of_therapy\": \"Individual.\",\n  \"preferred_therapist\": \"No preference.\",\n  \"reason_for_visit\": \"I'm having trouble managing my anger and it's affecting my relationships.\",\n  \"availability\": \"Evenings after work, and maybe Saturday mornings.\",\n  \"urgency\": \"High\",\n  \"insurance_company\": \"Blue Cross Blue Shield.\"\n}\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"def intake_form(form):\n    md_output = \"|   | Answer |\\n|----------|--------|\\n\"\n    for question, answer in form.items():\n        question_label = question.replace(\"_\", \" \").capitalize()\n        md_output += f\"| {question_label} | {answer} |\\n\"\n    return display(Markdown(md_output)) \nintake_form(client_intake)\n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T00:42:45.061571Z","iopub.execute_input":"2025-04-19T00:42:45.061903Z","iopub.status.idle":"2025-04-19T00:42:45.069145Z","shell.execute_reply.started":"2025-04-19T00:42:45.061880Z","shell.execute_reply":"2025-04-19T00:42:45.068192Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"|   | Answer |\n|----------|--------|\n| Name | Sarah Miller |\n| Phone number | 555-123-4567 |\n| Email | justleavemealone@invalid.com |\n| Age | 34 |\n| Type of therapy | Individual. |\n| Preferred therapist | No. |\n| Reason for visit | I'm just... overwhelmed. I can't seem to cope with anything lately. |\n| Availability | Evenings, after work. |\n| Urgency | High |\n| Insurance company | Ugh, Blue Cross Blue Shield. |\n"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"## **Structured Output**\n\n**Appointment Booking:**\nReceiving information from a client and returning in in JSON so it could be sent to database or booking system.\nFor interactive version check out [github](https://github.com/artamrz/GenAINotes/blob/393e15ff0e0838f797555493acd74d7fff805713/InteractiveStructuredOutputForBooking).\n","metadata":{}},{"cell_type":"code","source":"def convert_json(raw_response):\n    return(\n        raw_response.strip()\n        .removeprefix(\"```json\")\n        .removeprefix(\"```\")\n        .removesuffix(\"```\")\n        .strip()\n    )\nclient_request = \"Hi there, I'd like to book an appointment with Dr. Lean this friday anytime after 4pm. My name is Jake Abraham.\"\nbooking_prompt = f\"\"\"You are a Therapy centre assistant, A client will send a message to you to book an appointment.\nYour task:\n1. Extract the following information from the client's message:\n-client_name\n-phone_number\n-email\n-therapist_name\n-day\n-time\n        \n2.Return a JSON object with:\n5. Client: \"{client_request}\"   \n\"\"\"\n\nresponse = client.models.generate_content(\n        model = \"gemini-2.0-flash\",\n        contents = booking_prompt,\n        config = types.GenerateContentConfig(\n            temperature=0.1,\n            max_output_tokens=256\n        )\n    )\n    \nbooking_json = convert_json(response.text)\nbooking_data = json.loads(booking_json)\n\n\ntry: \n    booking_data = json.loads(booking_json)\n    display(Markdown(\"**Booking Infromation:**\"))\n    print(json.dumps(booking_data, indent=2))\nexcept json.JSONDecodeError as e:\n    print(\"Error: Invalid JSON output\")\n    print(booking_json)\n    print(f\"\\nJSON error: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T00:42:49.117023Z","iopub.execute_input":"2025-04-19T00:42:49.117423Z","iopub.status.idle":"2025-04-19T00:42:49.851706Z","shell.execute_reply.started":"2025-04-19T00:42:49.117398Z","shell.execute_reply":"2025-04-19T00:42:49.850639Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**Booking Infromation:**"},"metadata":{}},{"name":"stdout","text":"{\n  \"client_name\": \"Jake Abraham\",\n  \"phone_number\": \"unknown\",\n  \"email\": \"unknown\",\n  \"therapist_name\": \"Dr. Lean\",\n  \"day\": \"Friday\",\n  \"time\": \"After 4pm\"\n}\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"**Before going to the next cell**\n> There is an input version of collect_user_info (next cell) in the github, feel free to check it out, here, to run the whole notebook smoothly, two gemini based functions are used to demonstrate a booking process.","metadata":{}},{"cell_type":"code","source":"def collect_user_info(fields):\n    all_responses = \"\"\n    for field in fields:\n        question = field[\"question\"]\n        \n        user_prompt = f\"\"\"\n    You are simulating a therapy client. Sometimes you're calm, other times you're anxious or emotional. \n    Respond right away with a natural, human-like answer to the following intake question as if you're the client:\n    **TherapyBot:** {question}\n    Your tone should sound human — you may be unsure, emotional, hopeful, or hesitant — keep it short but real.\n    Only respond as the client. **DO NOT repeat the question or label who is speaking.**\n    \"\"\"\n    \n        response = client.models.generate_content(\n            model = \"gemini-2.0-flash\",\n            contents = user_prompt,\n            config = types.GenerateContentConfig(\n                temperature=1.0,\n                max_output_tokens=256\n            )\n        )\n        answer = response.text.strip()\n        all_responses += f\"**TherapyBot:** {question}\\n**Client:** {answer}\\n\\n\"\n    return all_responses.strip()\n\n    \nfields_to_ask = [\n    {\"key\": \"name\", \"question\": \"What is your full name?\"},\n    {\"key\": \"contact_info\", \"question\": \"May I have your email address or phone number?\"},\n    {\"key\": \"type_of_therapy\", \"question\": \"Are you looking for individual, couples, or family therapy?\"},\n    {\"key\": \"preferred_therapist\", \"question\": \"Do you have a preferred therapist?\"},\n    {\"key\": \"reason\", \"question\": \"Can you briefly describe your reason for seeking therapy?\"},\n    {\"key\": \"time\", \"question\": \"When do you want your session to be?\"}\n]   \nbooking_info = collect_user_info(fields_to_ask)\n\ndef gemini_booking_handler(bprompt):\n    \n    booking_prompt = f\"\"\"You are a Therapy centre assistant, A client will send a message to you to book an appointment.\n    Your task:\n    Extract the following information from the client's message:\n    -client_name\n    -contact-info\n    -therapist_name\n    -time\n            \n    Client: \"{bprompt}\"\n    \"\"\"\n    response = client.models.generate_content(\n            model = \"gemini-2.0-flash\",\n            contents = booking_prompt,\n            config = types.GenerateContentConfig(\n                temperature=0.1,\n                max_output_tokens=256\n            )\n        )\n    return response.text.strip()\n\ndisplay(Markdown(\"**Booking Scenario**\"))\ndisplay(Markdown(booking_info))\ndisplay(Markdown(\"**Booking Information**\"))\ndisplay(Markdown(gemini_booking_handler((booking_info))))\ndisplay(Markdown(\"**Oh! One last thing, the booking confirmation will be sent by email or text message. If the appointment is not confirmed within 24 hours, it will be automatically canceled and you can try again anytime!!**\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T02:15:25.370421Z","iopub.execute_input":"2025-04-19T02:15:25.370797Z","iopub.status.idle":"2025-04-19T02:15:29.313942Z","shell.execute_reply.started":"2025-04-19T02:15:25.370775Z","shell.execute_reply":"2025-04-19T02:15:29.312531Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**Booking Scenario**"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**TherapyBot:** What is your full name?\n**Client:** It's... Sarah Miller.\n\n**TherapyBot:** May I have your email address or phone number?\n**Client:** Um, yeah, sure. My number is 555-123-4567. Is this really going to help, though?\n\n**TherapyBot:** Are you looking for individual, couples, or family therapy?\n**Client:** Individual, I think. I mean, it's mostly about me, I guess.\n\n**TherapyBot:** Do you have a preferred therapist?\n**Client:** Not really. I just… I just need someone, I guess. Someone who gets it.\n\n**TherapyBot:** Can you briefly describe your reason for seeking therapy?\n**Client:** Well, things have just been...a lot lately. I'm having trouble coping with everyday life, I guess.\n\n**TherapyBot:** When do you want your session to be?\n**Client:** I'm honestly not sure. Maybe...late afternoon? Is that even an option? I don't know, I'm pretty flexible, I guess."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**Booking Information**"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Okay, I've reviewed the client's messages. Here's the information I've extracted:\n\n*   **client\\_name:** Sarah Miller\n*   **contact\\_info:** 555-123-4567\n*   **therapist\\_name:** No preference indicated.\n*   **time:** Late afternoon, flexible."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**Oh! One last thing, the booking confirmation will be sent by email or text message. If the appointment is not confirmed within 24 hours, it will be automatically canceled and you can try again anytime!!**"},"metadata":{}}],"execution_count":92},{"cell_type":"markdown","source":"## **Configure Additional Dataset** - (for Safe Conversation)\nFor the sake of this project, using an aditional dataset in the Psychology field was crucial. [The HuggingFace Mental Health Dataset](http://https://huggingface.co/datasets/Amod/mental_health_counseling_conversations) has more than 3.51 conversations during a counseling meeting. By this mean, if the user tries to make conversation the TherapyRobo can handle it more properly.","metadata":{}},{"cell_type":"markdown","source":"***First, loading the dataset...***\n\nI decided since I have limitations on Kaggle, not to load the whole dataset by spliting it so it would faster...","metadata":{}},{"cell_type":"code","source":"!pip install -q datasets\nfrom datasets import load_dataset\n\nhuggingface_dataset = load_dataset(\"Amod/mental_health_counseling_conversations\", split=\"train[:1000]\")\nhuggingface_dataset.column_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T00:44:13.661815Z","iopub.execute_input":"2025-04-19T00:44:13.662160Z","iopub.status.idle":"2025-04-19T00:44:21.988636Z","shell.execute_reply.started":"2025-04-19T00:44:13.662140Z","shell.execute_reply":"2025-04-19T00:44:21.987151Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/2.82k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"857c4707af0d43db8e7062da389294fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"combined_dataset.json:   0%|          | 0.00/4.79M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22c280be26ce4b42bc34c8b76829c659"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/3512 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"501803c701154851aa2075f09cdb5a15"}},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"['Context', 'Response']"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"***Generate embeddings...***","metadata":{}},{"cell_type":"code","source":"counsel_responses = [\n    ex[\"Response\"]\n    for ex in huggingface_dataset\n    if ex[\"Context\"] and ex[\"Response\"]\n]\n\n#embedding_hf_model = SentenceTransformer(\"all-miniLM-L6-v2\") I could do this, but I already have allminiLM in the model variable (Check Embeddings and Rag Section in the beginning)\nresponse_hf_embeddings = model.encode(counsel_responses, convert_to_tensor=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T00:44:25.322437Z","iopub.execute_input":"2025-04-19T00:44:25.322794Z","iopub.status.idle":"2025-04-19T00:45:22.408465Z","shell.execute_reply.started":"2025-04-19T00:44:25.322768Z","shell.execute_reply":"2025-04-19T00:45:22.407400Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c926099b02ee4c6d958c8e34c26e4153"}},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"***Indexing response***","metadata":{}},{"cell_type":"code","source":"index = faiss.IndexFlatL2(response_hf_embeddings.shape[1])\nindex.add(response_hf_embeddings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T00:45:39.763009Z","iopub.execute_input":"2025-04-19T00:45:39.763373Z","iopub.status.idle":"2025-04-19T00:45:39.769265Z","shell.execute_reply.started":"2025-04-19T00:45:39.763350Z","shell.execute_reply":"2025-04-19T00:45:39.768354Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"***RAG Search...***","metadata":{}},{"cell_type":"code","source":"def get_top_responses(query, top_n=3):\n    query_vector = model.encode([query], convert_to_numpy=True, show_progress_bar=False)\n    distances, indices = index.search(query_vector, top_n)\n    return [counsel_responses[i] for i in indices[0]]\n\ndef generate_rag_response(user_input, history = None):\n\n    history = history or []\n    \n    similar = get_top_responses(user_input)\n    context_block = \"\\n\".join([f\"- {resp}\" for resp in similar])\n    #history_text = \"\\n\".join([f\"User: {u}\\nTherapyBot: {r}\" for u, r in history])\n    history_text = \"\\n\".join([\n        f\"User: {u}\\nTherapyBot: {r}\"\n        for item in history\n        if isinstance(item, tuple) and len(item) == 2\n        for u, r in [item]\n    ])\n    rag_prompt = f\"\"\"\nYou are TherapyBot, a warm, emotionally intelligent virtual therapist.\nThe clinic website is: https://TherapyClinic.com and Phone number:+1 234 000 1111\nRespond briefly, kindly, and thoughtfully to the following client message in a realistic, supportive way.\nCheck if there is anything related to clients message in Therapy Dataset, use it summary of it to give the best response.\nNever use the direct conversations from dataset, recall them as \"we have experience with clients who\" but keep the answers short.\n\nConversation history: \"{history_text}\"\nClient says: {user_input}\nTherapy Dataset:\"{context_block}\"\nKeep responces short.\nTherapyRobo:\"\"\"\n\n    \n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=rag_prompt,\n        config=types.GenerateContentConfig(\n            temperature=0.1,\n            max_output_tokens=350\n        )\n    )\n    return response.text.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T02:24:48.377270Z","iopub.execute_input":"2025-04-19T02:24:48.377648Z","iopub.status.idle":"2025-04-19T02:24:48.385765Z","shell.execute_reply.started":"2025-04-19T02:24:48.377626Z","shell.execute_reply":"2025-04-19T02:24:48.384738Z"}},"outputs":[],"execution_count":105},{"cell_type":"markdown","source":"## **Agent**\n\nCreating an agent to detect what the user wants(booking, FAQ answering with RAG, intake forms, ...)\n\n> In here I am randomly choosing different scenarios for the agent, but the input version of the agent is available in github, please check it if you're interested.","metadata":{}},{"cell_type":"code","source":"import random\ndef agent_detect():\n        display(Markdown(\"**Therapy Clinic Assistant is with you, how can I help?**\\n\"))\n\n        history = []\n    \n        category = random.choice([\"faq\", \"booking\", \"document\"])\n        if \"faq\" in category:\n            faq_prompt = few_shot(user_input)\n            answer = gemini_faq_handler(faq_prompt)\n            display(Markdown(\"**FAQ Question**:\"))\n            display(Markdown(f\"**Client:** {sample_client}\"))\n            display(Markdown(f\"**TherapyRobo:** {answer}\"))\n            history.append((sample_client,answer))\n    \n        elif \"booking\" in category:\n            display(Markdown(\"**Booking Scenario**\\n\\n**Client**: I want to book an appointment\\n\"))\n            booking_rep = collect_user_info(fields_to_ask)\n            display(Markdown(booking_rep))\n            booking_result = gemini_booking_handler((booking_rep))\n            display(Markdown(booking_result))\n            display(Markdown(\"**Oh! One last thing, the booking confirmation will be sent by email or text message. If the appointment is not confirmed within 24 hours, it will be automatically canceled and you can try again anytime!!**\"))\n            history.append((\"client_booking_request\", booking_result))  \n    \n        elif \"document\" in category:\n            display(Markdown(\"**Client:** I want to make an account\"))\n            display(Markdown(\"**Starting to fill your intake form ...**\"))\n            client_intake, intake_conversation = collect_intake_info(intake_fields)\n            display(Markdown(intake_conversation))\n            intake_form(client_intake)\n            history.append((intake_conversation, \"Intake recorded\")) \n\n        display(Markdown(\"**After That The Client and TherapyRobo Make a Short Conversation**\"))\n        conversation_prompt_1 = f\"\"\"\n        You are simulating a therapy client.\n        You have already asked and FAQ questions, gave you information for the intake fomr, or booked an appointment, Check yhe history. \n        Sometimes you're calm, other times you're anxious or emotional. \n        say somthing related to history no thank you or bye yet.\n        Your answer should reflect a real human tone and emotional state but always moderately.\n        **Client**\n        history: \"{history}\"\n        \"\"\"\n        \n        response = client.models.generate_content(\n            model = \"gemini-2.0-flash\",\n            contents = conversation_prompt_1,\n            config = types.GenerateContentConfig(\n                temperature=1.0,\n                max_output_tokens=256\n                )\n        )\n        response_one = response.text.strip()\n        display(Markdown(f\"**Client:** {response_one}\"))\n        reply_one = generate_rag_response(response.text.strip(),history)\n        display(Markdown(f\"**TherapyRobo**: {reply_one}\"))\n        history.append((response_one, reply_one))\n    \n        conversation_prompt_2 = f\"\"\"\n        You are the same therapy client. Read history.\n        Now follow up with a final short message to thank TherapyBot for the support and say goodbye.\n        \n        Keep the tone warm, natural, and a little emotional — like you're truly appreciative.\n        history: \"{history}\"\n        Keep you response short\n        \"\"\"\n        \n        response = client.models.generate_content(\n            model = \"gemini-2.0-flash\",\n            contents = conversation_prompt_2,\n            config = types.GenerateContentConfig(\n                temperature=1.0,\n                max_output_tokens=256\n                )\n        )\n        response_two = response.text.strip()\n        display(Markdown(f\"**Client:** {response_two}\"))\n        reply_two = generate_rag_response(response.text.strip(),history)\n        display(Markdown(f\"**TherapyRobo**: {reply_two}\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T02:16:10.200265Z","iopub.execute_input":"2025-04-19T02:16:10.201325Z","iopub.status.idle":"2025-04-19T02:16:10.215091Z","shell.execute_reply.started":"2025-04-19T02:16:10.201269Z","shell.execute_reply":"2025-04-19T02:16:10.214065Z"}},"outputs":[],"execution_count":94},{"cell_type":"code","source":"agent_detect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T02:35:55.194491Z","iopub.execute_input":"2025-04-19T02:35:55.195266Z","iopub.status.idle":"2025-04-19T02:36:41.170661Z","shell.execute_reply.started":"2025-04-19T02:35:55.195224Z","shell.execute_reply":"2025-04-19T02:36:41.169144Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**Therapy Clinic Assistant is with you, how can I help?**\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**FAQ Question**:"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**Client:** Hey, I'm just wondering... what if I feel like my therapist isn't really listening to me? It's kinda frustrating."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**TherapyRobo:** That's a great idea. Trying a session is a perfect way to see if it's a good fit for you. You can book a session easily through our website at TherapyClinic.com or give us a call at +1 234 000 1111, and we'll be happy to assist you."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**After That The Client and TherapyRobo Make a Short Conversation**"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**Client:** It's just... I'm a little worried that what happened before might happen again, you know? I really need someone who's actually present and hears me this time."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**TherapyRobo**: I understand your worry about finding a therapist who truly listens. It's essential to feel heard and understood. We have experience with clients who have felt similarly, needing to process past experiences to move forward. At TherapyClinic.com, we emphasize creating a safe and supportive environment where your voice matters. We're here to help you find the right fit. You can explore therapist profiles on our website or call us at +1 234 000 1111, and we can discuss your needs to ensure a better experience this time."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**Client:** Thank you so much for everything. Talking through this has really helped me feel more confident about taking the next step. I think I'm ready to move forward now. Goodbye, and thanks again for being there."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**TherapyRobo**: I'm so glad to hear that our conversation has been helpful and that you feel more confident about moving forward. It takes courage to take these steps, and I commend you for your willingness to prioritize your well-being. We have experience with clients who have found that processing their feelings and concerns can be incredibly empowering. Remember, we're here at TherapyClinic.com and +1 234 000 1111 if you need further support in the future. Wishing you all the best on your journey!"},"metadata":{}}],"execution_count":119},{"cell_type":"markdown","source":"**Note**\n\n> As the Google Gen AI capston project should run smoothly and end to end the responses for the TherapyRobo were generated by gemini in a role of client.If you wanted to use the Therapy Robo and chat with its agent, check the interctive version.\n","metadata":{}},{"cell_type":"markdown","source":"# **The End**","metadata":{}}]}